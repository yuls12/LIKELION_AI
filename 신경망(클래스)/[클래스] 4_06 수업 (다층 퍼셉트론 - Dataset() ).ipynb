{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "federal-emergency",
   "metadata": {},
   "source": [
    "Dataset() 클래스\n",
    "\n",
    "    다양한 종류의 데이터셋 지원에 필요한 공통 기능을 제공하면서 여러가지 데이터셋 클래스들의 기반 클래스 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "skilled-terminology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:48:35.173898Z",
     "start_time": "2021-04-12T07:48:35.168895Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\gowra\\\\1_멋쟁이 사자처럼\\\\2. 신경망 기법\\\\신경망(클래스_프로그램_제작_프로젝트)/code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "literary-fairy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T07:48:36.494918Z",
     "start_time": "2021-04-12T07:48:35.836548Z"
    }
   },
   "outputs": [],
   "source": [
    "%run mathutil.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, name, mode):  # 초기화 (이름/유형)\n",
    "        self.name = name\n",
    "        self.mode = mode\n",
    "\n",
    "    def __str__(self):  # 문자열 초기화 메서드\n",
    "        return '{}({}, {}+{}+{})'.format(self.name, self.mode, len(self.tr_xs),\n",
    "                                         len(self.te_xs), len(self.va_xs)) \n",
    "\n",
    "    @property  # 함수가 아닌 속성으로 취급해주는 데코레이터\n",
    "    def train_count(self):\n",
    "        return len(self.tr_xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-policy",
   "metadata": {},
   "source": [
    "    메서드는 초기화  __init__() 메서드, 문자열화  __str__() 메서드가 정의\n",
    "\n",
    "    초기화 메서드에서는 데이터셋 이름과 출력의 유형을 의미하는 모드값을 챙겨 저장합니다. \n",
    "    모드(mode)의 경우 회귀 분석, 이진 분류, 다중 선택 분류를 나타내는 'regression', 'binary', 'select' 로 구분하여 문제를 해결\n",
    "\n",
    "    문자열화 메서드의 경우 출력 유형을 설정할 수 있는데, \n",
    "    데이터셋, 모드유형, 학습 데이터의 크기, 테스트 데이터의 크기, 검증 데이터의 크기 이렇게 다섯가지 정보를 각각 표현\n",
    "\n",
    "    학습 데이터 셋의 수를 반환하는 train_count() 메서드 \n",
    "    실제로는 함수 메서드이지만 함수가 아닌 속성으로 취급되며 x.train_count() 형식 대신 x.train_count 형식으로 접근\n",
    "\n",
    "    MlpModel() 클래스의 train() 메서드에서 batch_count = int(self.dataset.train_count / batch_size) 의 구조를 살펴보면\n",
    "    self.dataset.train_count 처럼 함수의 형식이 아니지만 접근이 가능한 것을 확인할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-boulder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "automatic-encounter",
   "metadata": {},
   "source": [
    "#### 학습 데이터를 분할 dataset_get_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_train_data(self, batch_size, nth):\n",
    "    from_idx = nth * batch_size\n",
    "    to_idx = (nth + 1) * batch_size\n",
    "\n",
    "    tr_X = self.tr_xs[self.indices[from_idx:to_idx]]\n",
    "    tr_Y = self.tr_ys[self.indices[from_idx:to_idx]]\n",
    "\n",
    "    return tr_X, tr_Y\n",
    "\n",
    "\n",
    "def dataset_shuffle_train_data(self, size):\n",
    "    self.indices = np.arange(size)\n",
    "    np.random.shuffle(self.indices)\n",
    "\n",
    "Dataset.get_train_data = dataset_get_train_data\n",
    "Dataset.shuffle_train_data = dataset_shuffle_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-appreciation",
   "metadata": {},
   "source": [
    "    학습 데이터를 분할하는 과정은 위에서 살펴본 전체 학습 데이터의 수인 train_count를 우리가 설정한 batch_size 로 나누게 되면 학습 데이터가 batch_count로 얼마나 나뉘어 지는지 알 수 있다. \n",
    "\n",
    "    미니배치 단위를 인덱스로 구분하고, 구분되어진 인덱스 범위에서 tr_X,  tr_Y 를 구분하여 줍니다. \n",
    "\n",
    "    self.indices 는 아래 메서드를 통해 한 차례 무작위로 섞인 인덱스로, 그 인덱스의 범위를 슬라이싱하여 저장\n",
    "\n",
    "    반복문  을 활용하여 batch_count를 순차적으로 nth 에 할당, \n",
    "    그리고 사전에 정의된 batch_size 값과의 연산을 통해 batch_size로 지정한 크기만큼 from_idx와 to_idx를 반복적으로 구해줄 수 있게된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-colon",
   "metadata": {},
   "source": [
    "    매번 같은 패턴으로 에폭값이 늘어나게 되면 학습은 제대로 진행되지 않습니다.\n",
    "    그래서 한 차례 에폭이 진행 될 때마다 데이터를 무작위로 섞어주는 과정이 필요하게 됩니다\n",
    "\n",
    "    dataset_shuffle_train_data() 메서드에서 정의\n",
    "\n",
    "    batch_size와 batch_count의 곱한 값을 numpy의 arange()를 통해 실제 사용되는 학습 데이터를 인덱스로 생성하고, \n",
    "    이렇게 생성된 인덱스를 np.random.shuffle()를 통해 무작위로 섞어 제공\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-taiwan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "varied-square",
   "metadata": {},
   "source": [
    "#### 테스트 데이터와 검증 데이터에 대한 분할과정 dataset_get_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_test_data(self):\n",
    "    return self.te_xs, self.te_ys\n",
    "\n",
    "Dataset.get_test_data = dataset_get_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-sense",
   "metadata": {},
   "source": [
    "    dataset_get_test_data() 의 경우 mlp_model_test() 메서드에서 사용되어지는 메서드로, \n",
    "    별 다른 처리 없이 테스트 데이  터인 te_xs, te_ys 를 전달 받게 됩니다. \n",
    "\n",
    "    마지막 코드를 보면 하나의 메서드를 Dataset() 클래스의 두 메서드로 정의되는 것을 확인할 수 있다. \n",
    "\n",
    "    이 방식은  메서드를 외부에서 정의하고 클래스의 내부에 같은 기능을 하는 메서드를 다른 이름으로 정의할 수 있게 해줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-cliff",
   "metadata": {},
   "source": [
    "#### 검증데이터 분할 / 시각화 dataset_get_validate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_validate_data(self, count):\n",
    "    self.va_indices = np.arange(len(self.va_xs))\n",
    "    np.random.shuffle(self.va_indices)\n",
    "\n",
    "    va_X = self.va_xs[self.va_indices[0:count]]\n",
    "    va_Y = self.va_ys[self.va_indices[0:count]]\n",
    "\n",
    "    return va_X, va_Y\n",
    "\n",
    "Dataset.get_validate_data = dataset_get_validate_data\n",
    "Dataset.get_visualize_data = dataset_get_validate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-tsunami",
   "metadata": {},
   "source": [
    "    검증 데이터 분할 메서드 get_validate_data()\n",
    "    mlp_model_train() 메서드에서 조건에 만족한 경우에만 아래와 같은 방식으로 수행\n",
    "\n",
    "    원하는 수 만큼의 count 매개 변수를 전달받게 되는데, \n",
    "    우선 self.va_xs는 이후에 살펴보겠지만 전체 데이터에서 원하는 비율만큼의 va_ratio를 설정하여 얻어진 검증 데이터의 독립 변수 데이터라 할 수 있습니다.\n",
    "    그래서 np.arange()를 통해 검증 데이터의 인덱스를 확보하고, 그 인덱스를 한번 무작위로 섞어 줍니다.\n",
    "\n",
    "    그리고 검증 데이터셋인 self.va_xs에 무작위로 섞인 인덱스 self.va_indices 로 접근하여 앞서 설정한 count 수 만큼의 데이터를 va_X에 할당하여 줍니다. \n",
    "    결과적으로  va_ratio비율의 검증 데이터셋에서 무작위로 섞인 count 수 만큼의 검증 데이터를 va_X에 할당한 것 입니다. \n",
    "\n",
    "    종속 변수도 같은 방식으로 하여 va_Y 를 돌려받아 줄 수 있습니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-gender",
   "metadata": {},
   "source": [
    "#### 변수들을 정의 dataset_shuffle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_shuffle_data(self, xs, ys, tr_ratio=0.8, va_ratio=0.05):\n",
    "    data_count = len(xs)\n",
    "\n",
    "    tr_cnt = int(data_count * tr_ratio / 10) * 10\n",
    "    va_cnt = int(data_count * va_ratio)\n",
    "    te_cnt = data_count - (tr_cnt + va_cnt)\n",
    "\n",
    "    tr_from, tr_to = 0, tr_cnt\n",
    "    va_from, va_to = tr_cnt, tr_cnt + va_cnt\n",
    "    te_from, te_to = tr_cnt + va_cnt, data_count\n",
    "\n",
    "    indices = np.arange(data_count)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    self.tr_xs = xs[indices[tr_from:tr_to]]\n",
    "    self.tr_ys = ys[indices[tr_from:tr_to]]\n",
    "    self.va_xs = xs[indices[va_from:va_to]]\n",
    "    self.va_ys = ys[indices[va_from:va_to]]\n",
    "    self.te_xs = xs[indices[te_from:te_to]]\n",
    "    self.te_ys = ys[indices[te_from:te_to]]\n",
    "\n",
    "    self.input_shape = xs[0].shape\n",
    "    self.output_shape = ys[0].shape\n",
    "    \n",
    "    return indices[tr_from:tr_to], indices[va_from:va_to], indices[te_from:te_to]\n",
    "\n",
    "Dataset.shuffle_data = dataset_shuffle_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-triumph",
   "metadata": {},
   "source": [
    "    tr_xs, te_xs, va_xs … 등의 변수들을 정의\n",
    "    Dataset_chap123.ipynb 파일의 각 데이터셋을 다루는 클래스들에서 사용되어 집니다. \n",
    "\n",
    "    전체 데이터의 독립 변수와 종속변수, 학습 데이터 비율, 검증 데이터 비율값을 전달받아 \n",
    "    학습 데이터, 검증 데이터, 테스트 데이터로 각각 나눠지게 된다.\n",
    "\n",
    "    전체 데이터의 독립 변수인 xs에 len()를 적용하여 data_count 값을 구해줍니다\n",
    "\n",
    "    구한 값과 tr_ratio,  va_ratio 를 활용하여 학습 데이터(tr_cnt)와 검증 데이터(va_cnt)의 수를 구해주고, \n",
    "    전체 수인 data_count 에서 위의 값을 빼주게 되면 자연스럽게 테스트 데이터의 수(te_cnt)를 얻어낼 수 있게 됩니다. \n",
    "\n",
    "    인덱스로  나누기위해 각 데이터 별로 시작 지점과 끝 지점을 지정하는 과정을 수행해줍니다. \n",
    "    그리고 데이터를 할당하기 위하여 전체 데이터의 인덱스를 np.arange()로 구해주고, \n",
    "    그 값을 np.random.shuffle()로 무작위로 섞어주겠습니다.\n",
    "    \n",
    "    학습 데이터, 검증 데이터, 테스트 데이터를 독립 변수와 종속 변수로 구분하여 저장\n",
    "    MlpModel() 클래스의 파라미터 초기화 메서드를 정의하는 과정에서 input_shape과 output_shape를 Dataset() 클래스에서 정의한다 하였습니다.\n",
    "    이 메서드에서는 독립 변수와 종속 변수를 받아왔기에 각 xs, ys의 첫 번째 행의 열 개수 즉, 입출력 벡터의 크기를 설정해 줄 수가 있습니다.  \n",
    "    마지막으로 반환값은 각 데이터들의 원래 위치를 알 필요가 있을 때 를 대비하여 준비하였습니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-weather",
   "metadata": {},
   "source": [
    "#### 순전파 과정⭐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_forward_postproc(self, output, y, mode=None):\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression':\n",
    "        diff = output - y\n",
    "        square = np.square(diff)\n",
    "        loss = np.mean(square)\n",
    "        aux = diff\n",
    "    elif mode == 'binary':\n",
    "        entropy = sigmoid_cross_entropy_with_logits(y, output)\n",
    "        loss = np.mean(entropy)\n",
    "        aux = [y, output]\n",
    "    elif mode == 'select':\n",
    "        entropy = softmax_cross_entropy_with_logits(y, output)\n",
    "        loss = np.mean(entropy)\n",
    "        aux = [output, y, entropy]\n",
    "        \n",
    "    return loss, aux\n",
    "\n",
    "Dataset.forward_postproc = dataset_forward_postproc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-number",
   "metadata": {},
   "source": [
    "    MlpModel() 클래스에서 정의되는 mlp_forward_postproc() 메서드에서는 ‘입력값’으로 신경망의 예측인 output 과 실제 정답인 y 가 들어오게 되었을 때, 바로 손실을 구하지 않고 문제의 성격에 맞게 동작을 수행\n",
    "\n",
    "    dataset_forward_postproc() 이 메서드의 경우 세 가지 문제에 대한 손실과 이후 손실에 대한 역전파를 수행하기 위한 보조 지표를 반환시켜 주었습니다. \n",
    "    수행 방식은 init 초기화 메서드에서 정의된 mode 를 전달받아 if, else 조건문을 활용하여 mode 의 성격에 맞는 손실을 구하는 과정으로 정의합니다. \n",
    "    그리고 손실함수의 역전파 과정을 위한 aux 도 챙겨주도록 하였습니다.\n",
    "\n",
    "    dataset_chap123.ipynb 에서 살펴볼 각 데이터별 클래스에서 Dataset() 클래스를 상속받아 데이터 이름과 모드를 문제 성격에 맞게 설정 후 \n",
    "    클래스 변수화 시켜 줄 수 있고, 이를 MlpModel() 클래스의 dataset 에 할당시켜 다층 퍼셉트론 신경망 구축을 위한 파라미터 초기화 과정을 수행시켜 줍니다. \n",
    "    그리고 이는 Model() 클래스에 상속되어 있기에 Model() 클래스의 exec_all() 메서드를 적용하여 학습, 테스트, 시각화 과정을 순차적으로 수행\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-moral",
   "metadata": {},
   "source": [
    "#### 손실 함수의 기울기를 구하는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_backprop_postproc(self, G_loss, aux, mode=None):\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression':\n",
    "        diff = aux\n",
    "        shape = diff.shape\n",
    "\n",
    "        g_loss_square = np.ones(shape) / np.prod(shape)\n",
    "        g_square_diff = 2 * diff\n",
    "        g_diff_output = 1\n",
    "\n",
    "        G_square = g_loss_square * G_loss\n",
    "        G_diff = g_square_diff * G_square\n",
    "        G_output = g_diff_output * G_diff\n",
    "    elif mode == 'binary':\n",
    "        y, output = aux\n",
    "        shape = output.shape\n",
    "\n",
    "        g_loss_entropy = np.ones(shape) / np.prod(shape)\n",
    "        g_entropy_output = sigmoid_cross_entropy_with_logits_derv(y, output)\n",
    "\n",
    "        G_entropy = g_loss_entropy * G_loss\n",
    "        G_output = g_entropy_output * G_entropy\n",
    "    elif mode == 'select':\n",
    "        output, y, entropy = aux\n",
    "\n",
    "        g_loss_entropy = 1.0 / np.prod(entropy.shape)\n",
    "        g_entropy_output = softmax_cross_entropy_with_logits_derv(y, output)\n",
    "\n",
    "        G_entropy = g_loss_entropy * G_loss\n",
    "        G_output = g_entropy_output * G_entropy\n",
    "    \n",
    "    return G_output\n",
    "\n",
    "Dataset.backprop_postproc = dataset_backprop_postproc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-publicity",
   "metadata": {},
   "source": [
    "    MlpModel() 클래스에서 mlp_backprop_postproc() 메서드로 정의되어 지지만, 메서드 정의 과정을 살펴보면 \n",
    "    다시 dataset_backprop_postproc() 에서 G_output을 산출\n",
    "\n",
    "    주어진 mode에 맞춰 회귀 분석, 이진 분류, 선택 분류에 대한 손실 함수의 역전파 과정을 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-heading",
   "metadata": {},
   "source": [
    "#### 평가와 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_eval_accuracy(self, x, y, output=None):  \n",
    "    if output is None:\n",
    "        output, _ = self.forward_neuralnet(x)\n",
    "    accuracy = self.dataset.eval_accuracy(x, y, output)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-modem",
   "metadata": {
    "code_folding": [
     11
    ]
   },
   "outputs": [],
   "source": [
    "def dataset_eval_accuracy(self, x, y, output, mode=None):\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression':\n",
    "        mse = np.mean(np.square(output - y))\n",
    "        accuracy = 1 - np.sqrt(mse) / np.mean(y)\n",
    "    elif mode == 'binary':\n",
    "        estimate = np.greater(output, 0)\n",
    "        answer = np.equal(y, 1.0)\n",
    "        correct = np.equal(estimate, answer)\n",
    "        accuracy = np.mean(correct)\n",
    "    elif mode == 'select':\n",
    "        estimate = np.argmax(output, axis=1)\n",
    "        answer = np.argmax(y, axis=1)\n",
    "        correct = np.equal(estimate, answer)\n",
    "        accuracy = np.mean(correct)\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "Dataset.eval_accuracy = dataset_eval_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-industry",
   "metadata": {},
   "source": [
    "#### 예측 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_get_estimate(self, x):\n",
    "    output, _ = self.forward_neuralnet(x)  # 신경망의 결과\n",
    "    estimate = self.dataset.get_estimate(output)  # 신경망의 결과를 가지고 예측\n",
    "    \n",
    "    return estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_estimate(self, output, mode=None):\n",
    "    if mode is None: mode = self.mode\n",
    "        \n",
    "    if mode == 'regression':\n",
    "        estimate = output\n",
    "    elif mode == 'binary':\n",
    "        estimate = sigmoid(output)\n",
    "    elif mode == 'select':\n",
    "        estimate = softmax(output)\n",
    "        \n",
    "    return estimate\n",
    "\n",
    "Dataset.get_estimate = dataset_get_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-occupation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_train_prt_result(self, epoch, costs, accs, acc, time1, time2):\n",
    "    print('    Epoch {}: cost={:5.3f}, accuracy={:5.3f}/{:5.3f} ({}/{} secs)'. \\\n",
    "          format(epoch, np.mean(costs), np.mean(accs), acc, time1, time2))\n",
    "\n",
    "def dataset_test_prt_result(self, name, acc, time):\n",
    "    print('Model {} test report: accuracy = {:5.3f}, ({} secs)\\n'. \\\n",
    "          format(name, acc, time))\n",
    "\n",
    "Dataset.train_prt_result = dataset_train_prt_result\n",
    "Dataset.test_prt_result = dataset_test_prt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-frederick",
   "metadata": {},
   "source": [
    "    dataset_train_prt_result()의 경우 mlp_model_train() 에서 조건문에 따른 report로 설정한 주기에 맞춰 수행 결과를 출력하게끔 설계된 메서드로,\n",
    "    출력에 필요한 매개 변수를 전달받아 에폭 횟수, 학습 단계의 비용과 정확도, 검증 데이터의 정확도, 한 에폭마다 걸린시간과 누적 소요시간을 출력하게 됩니다. \n",
    "    단, 학습 데이터를 통한 비용과 정확도는 미니배치 마다 구해진 다수의 결괏값의 평균치로 출력하였습니다.  \n",
    "\n",
    "    마찬가지로 dataset_test_prt_result() 의 경우에는 테스트 데이터를 바탕으로 진행된 결과를 출력하기에 어떠한 모델을 사용했는지, \n",
    "    평가에 소요된 시간은 얼마나 되는지를 함께 출력하도록 설계하였습니다. \n",
    "\n",
    "    최종 출력결과를 함께 살펴보면 조금 더 쉽게 이해할 수 있습니다. \n",
    "    하단에 학습에 걸린 총 시간 같은 경우 mlp_model_train() 의 모든 반복 학습이 완료되었을 때 출력되어지는 문자열이기에 \n",
    "    당연히 mlp_model_test() 메서드의 dataset_test_prt_result() 결과는 그 아래에 출력되어 집니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-spare",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "local-question",
   "metadata": {},
   "source": [
    "``` python\n",
    "class Model(object):\n",
    "    …\n",
    "    def exec_all(self, epoch_count=10, batch_size=10, learning_rate=0.001,  report=0, show_cnt=3):\n",
    "        self.train(epoch_count, batch_size, learning_rate, report)\n",
    "        self.test()\n",
    "\n",
    "\n",
    "def mlp_model_train(self, epoch_count=10, batch_size=10, learning_rate=0.001, report=0):\n",
    "    …\n",
    "    for epoch in range(epoch_count):\n",
    "        …\n",
    "        for n in range(batch_count):\n",
    "        …\n",
    "        if report > 0 and (epoch+1) % report == 0:\n",
    "            …\n",
    "            self.dataset.train_prt_result(epoch+1, costs, accs, acc, tm1, tm2)\n",
    "\n",
    "\n",
    "MlpModel.train = mlp_model_train  # Model class의 train에서 돌아감\n",
    "\n",
    "def dataset_train_prt_result(self, epoch, costs, accs, acc, time1, time2):  \n",
    "    print('\tEpoch {}: cost={:5.3f}, accuracy={:5.3f}/{:5.3f} ({}/{} secs)'.format(\n",
    "        epoch, np.mean(costs), np.mean(accs), acc, time1, time2))\n",
    "\n",
    "Dataset.train_prt_result = dataset_train_prt_result\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-bacteria",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-contribution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
